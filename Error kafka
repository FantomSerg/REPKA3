echo "Hello Kafka" | docker-compose exec -T kafka kafka-console-producer --broker-list localhost:9092 --topic test-topic

curl -v -x http://ser-technicak-proxy.kamyk.ru:4522 https://api.yandex.net
You need to install \"jmespath\" prior to running json_query filter


Warning: Identity file /data/im-user/.ssh/pk not accessible: No such file or directory.
Authorized uses only. All activity may be monitored and reported.
Use your AD login on this server (Quest VAS)


Warning:
The JKS keystore uses a proprietary format. It is recommended to migrate to PKCS12 which is an industry standard format using
[2024-12-13 06:02:37,245] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Failed authentication with /172.21.0.1 (channelId=172.21.0.6:9092-172.21.0.1:12294-0) (SSL handshake failed) (org.apache.kafka.common.network.Selector)
=========================================
Can't use SSL_get_servername
depth=0 C = RU, ST = Moscow, L = Moscow, O = Otus, OU = Kafka, CN = broker-111
verify error:num=18:self-signed certificate
verify return:1
depth=0 C = RU, ST = Moscow, L = Moscow, O = Otus, OU = Kafka, CN = broker-111
verify return:1

Requested Signature Algorithms: ECDSA+SHA256:ECDSA+SHA384:ECDSA+SHA512:Ed25519:Ed448:RSA-PSS+SHA256:RSA-PSS+SHA384:RSA-PSS+SHA512:RSA-PSS+SHA256:RSA-PSS+SHA384:RSA-PSS+SHA512:RSA+SHA256:RSA+SHA384:RSA+SHA512:ECDSA+SHA1:RSA+SHA1
Shared Requested Signature Algorithms: ECDSA+SHA256:ECDSA+SHA384:ECDSA+SHA512:Ed25519:Ed448:RSA-PSS+SHA256:RSA-PSS+SHA384:RSA-PSS+SHA512:RSA-PSS+SHA256:RSA-PSS+SHA384:RSA-PSS+SHA512:RSA+SHA256:RSA+SHA384:RSA+SHA512
Peer signing digest: SHA256
Peer signature type: RSA-PSS
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 1573 bytes and written 335 bytes
Verification error: self-signed certificate
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 18 (self-signed certificate)
---
Certificate chain
 0 s:C = RU, ST = Moscow, L = Moscow, O = Otus, OU = Kafka, CN = broker-111
   i:C = RU, ST = Moscow, L = Moscow, O = Otus, OU = Kafka, CN = broker-111
   a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256
   v:NotBefore: Dec  8 18:10:14 2024 GMT; NotAfter: Dec  8 18:10:14 2025 GMT
=======================
openssl s_client -connect 172.20.0.6:9092 -tls1
CONNECTED(00000003)
40B785636
2780000:error:0A0000BF:SSL routines:tls_setup_handshake:no protocols available:../ssl/statem/statem_lib.c:104:
---
no peer certificate available
---
No client certificate CA names sent
---
SSL handshake has read 0 bytes and written 7 bytes
Verification: OK
---
New, (NONE), Cipher is (NONE)
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
================
[2024-12-12 16:06:41,750] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.kafka.common.KafkaException: Failed to load SSL keystore /etc/kafka/secrets/vlg-im-kafka01t.megafon.ru.jks of type JKS

=====================
- KAFKA_CLUSTERS_0_READONLY=false

[2024-12-09 08:02:05,203] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
=========


[2024-12-08 18:58:14,601] TRACE [Broker id=2] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=6, leader=1, leaderEpoch=5, isr=[1], partitionEpoch=6, replicas=[2, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 3 from controller 1 epoch 6 (state.change.logger)
error from daemon in stream: Error grabbing logs: invalid character '\x00' looking for beginning of value
[2024-12-08 18:58:13,516] TRACE [Broker id=2] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 6 starting the become-follower transition for partition __consumer_offsets-3 with leader -1 (state.change.logger)

============================
[2024-12-08 18:56:08,561] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.lang.IllegalArgumentException: Error creating broker listeners from 'PLAINTEXT://broker-111:29092,SSL:///172.20.0.6:9092': Unable to parse SSL:///172.20.0.6:9092 to a broker endpoint
[2024-12-08 18:53:24,058] ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
java.lang.IllegalArgumentException: requirement failed: advertised.listeners cannot use the nonroutable meta-address 0.0.0.0. Use a routable IP address.
=============================================================
ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)
org.apache.kafka.common.config.ConfigException: Listener with name PLAINTEXT:// defined in inter.broker.listener.name not found in listener.security.protocol.map.
====================
ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.kafka.common.config.ConfigException: Invalid value javax.net.ssl.SSLHandshakeException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target for configuration A client SSLEngine created with the provided settings can't connect to a server SSLEngine created with those settings.
=============================
[2024-12-06 18:33:02,360] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.kafka.common.config.ConfigException: Invalid value javax.net.ssl.SSLHandshakeException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target for configuration A client SSLEngine created with the provided settings can't connect to a server SSLEngine created with those settings.
=======================================================

ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.kafka.common.config.ConfigException: Invalid value javax.net.ssl.SSLHandshakeException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target for configuration A client SSLEngine created with the provided settings can't connect to a server SSLEngine created with those settings.
=================================
keytool -exportcert -alias mykey -keystore kafka.keystore.jks -file certificate.crt -storepass qwe123
Certificate stored in file <certificate.crt>

Warning:
The JKS keystore uses a proprietary format. It is recommended to migrate to PKCS12 which is an industry standard format using "keytool -importkeystore -srckeystore kafka.keystore.jks -destkeystore kafka.keystore.jks -deststoretype pkcs12".
==============================
keytool -importcert -alias mykey -file certificate.crt -keystore kafka.keystore.jks -storepass qwe123
keytool error: java.lang.Exception: Certificate reply and certificate in keystore are identical
==========================
Could not open file or uri for loading private key from -inkey file from privatkey.key
4017D006C37B0000:error:16000069:STORE routines:ossl_store_get0_loader_int:unregistered scheme:../crypto/store/store_register.c:237:scheme=file
4017D006C37B0000:error:8000000D:system library:BIO_new_file:Permission denied:../crypto/bio/bss_file.c:67:calling fopen(privatkey.key, rb)
4017D006C37B0000:error:10080002:BIO routines:BIO_new_file:system lib:../crypto/bio/bss_file.c:77:
=================
[2024-12-06 11:48:00,829] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.kafka.common.config.ConfigException: Invalid value javax.net.ssl.SSLHandshakeException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target for configuration A client SSLEngine created with the provided settings can't connect to a server SSLEngine created with those settings.
================================
KAFKA_SSL_KEYSTORE_FILENAME: "keystore.jks"
      KAFKA_SSL_KEYSTORE_CREDENTIALS: "kafka_cred"
      KAFKA_SSL_KEY_CREDENTIALS: "/etc/kafka/secrets"
      KAFKA_SSL_TRUSTSTORE_FILENAME: "keystore.jks"
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: "kafka_cred"

    volumes:
      - /home/fanta/Desktop/Kafka/ssl/secrets:/etc/kafka/secrets 
=====================
===> User
uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
===> Configuring ...
Running in Zookeeper mode...
SSL is enabled.
KAFKA_SSL_KEY_CREDENTIALS is required.
Command [/usr/local/bin/dub ensure KAFKA_SSL_KEY_CREDENTIALS] FAILED !
==============================
package:
	gradle -PartifactoryUsername=${USER} -PartifactoryPassword=${PASSWORD} clean bootJar 

==============
cp: cannot stat '/data/jenkins/volume/workspace/middleves/vecom/kalmyk-services/kalmyk-app/ci-job/build/libs/*.jar': No such file or directory
make: *** [/data/jenkins/volume/workspace/middleves/vecom/kalmyk-goodremains-services/kalmyk-app/ci-job/product/buildpack/Makefile:28: copy] Error 1

KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-222:29093,PLAINTEXT_HOST://172.20.0.5:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

KAFKA_CLUSTERS_0_SCHEMAREGISTRY_URL:
image: provectuslabs/kafka-ui:<latest_version>  # Укажите последнюю стабильную версию
    container_name: kafka-ui
    ports:
      - "8082:8080"  # Порт для доступа к Kafka UI
    depends_on:
      - broker-111
      - broker-222
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
      KAFKA_CLUSTERS_0_NAME: 'local'
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: 'PLAINTEXT://broker-111:29092,PLAINTEXT://broker-222:29093' 
      KAFKA_CLUSTERS_0_SCHEMA_REGISTRY_URLS: 'http://schemaregistry:8081'  # URL для Schema Registry
    networks:
      - kafka-net
============================
024-12-02 11:58:29,782 ERROR [reactor-http-epoll-3] o.s.b.a.w.r.e.AbstractErrorWebExceptionHandler: [29d5eb15-25]  500 Server Error for HTTP GET "/api/clusters/local/schemas?page=1&perPage=25"
org.springframework.web.reactive.function.client.WebClientRequestException: finishConnect(..) failed: Connection refused: schemaregistry/172.19.0.7:8085
        at org.springframework.web.reactive.function.client.ExchangeFunctions$DefaultExchangeFunction.lambda$wrapException$9(ExchangeFunctions.java:136)
        Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException:

==========================
ec 02, 2024 11:03:23 AM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
WARNING: A provider io.confluent.kafka.schemaregistry.rest.resources.ConfigResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider io.confluent.kafka.schemaregistry.rest.resources.ConfigResource will be ignored.

===========================
500 Internal Server Error
["http://localhost:8085"] is not a valid HTTP URL
====================
[2024-12-02 10:50:38,849] ERROR Server died unexpectedly:  (io.confluent.kafka.schemaregistry.rest.SchemaRegistryMain)
org.apache.kafka.common.config.ConfigException: No supported Kafka endpoints are configured. kafkastore.bootstrap.servers must have at least one endpoint matching kafkastore.security.protocol.
SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://broker-111:29092,PLAINTEXT://broker-222:29093'
KAFKA_SECURITY_PROTOCOL: PLAINTEXT
============================> User
uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
===> Configuring ...
Running in Zookeeper mode...
===> Running preflight checks ... 
===> Check if /var/lib/kafka/data is writable ...
Command [/usr/local/bin/dub path /var/lib/kafka/data writable] FAILED !
===> User
uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
===> Configuring ...
Running in Zookeeper mode...
===> Running preflight checks ... 
===> Check if /var/lib/kafka/data is writable ...
Command [/usr/local/bin/dub path /var/lib/kafka/data writable] FAILED !

===========================
volumes:
      - /home/fanta/Documents/kafka-data:/var/lib/kafka/data

validating /home/fanta/Desktop/Kafka/docker-compose.yaml: volumes Additional property /home/fanta/Documents/kafka-data is not allowed
    volumes:
      - type: bind
        source: /home/fanta/Documents/kafka-data
        target: /kafka/data

===========================================
2024-11-26 17:25:45 [2024-11-26 13:25:45,430] WARN Cannot open channel to 2 at election address localhost/127.0.0.1:13888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
2024-11-26 17:25:45 java.net.ConnectException: Connection refused (Connection refused)
2024-11-26 17:25:45     at java.net.PlainSocketImpl.socketConnect(Native Method)
2024-11-26 17:25:45     at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
2024-11-26 17:25:45     at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
2024-11-26 17:25:45     at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
2024-11-26 17:25:45     at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
2024-11-26 17:25:45     at java.net.Socket.connect(Socket.java:589)
2024-11-26 17:25:45     at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:650)
2024-11-26 17:25:45     at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:707)
2024-11-26 17:25:45     at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectAll(QuorumCnxManager.java:735)
2024-11-26 17:25:45     at org.apache.zookeeper.server.quorum.FastLeaderElection.lookForLeader(FastLeaderElection.java:910)
2024-11-26 17:25:45     at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:1247)
====================================================
2024-11-26 17:24:15 [2024-11-26 13:24:15,826] WARN Cannot open channel to 2 at election address localhost/127.0.0.1:13888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
2024-11-26 17:24:15 java.net.ConnectException: Connection refused (Connection refused)
=================================================
ZOOKEEPER_QUORUM_LISTEN_ON_ALL_IPS: 'true
[2024-11-23 22:40:58,958] INFO Opening socket connection to server zookeeper/172.20.0.4:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-23 22:40:58,958] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2024-11-23 22:40:58,959] INFO Socket connection established, initiating session, client: /172.20.0.6:38924, server: zookeeper/172.20.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-23 22:40:58,960] WARN Session 0x0 for server zookeeper/172.20.0.4:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x0, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)

=====================
[2024-11-23 22:41:02,974] WARN Session 0x0 for server zookeeper2/172.20.0.2:12181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x0, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
fanta@Ubuntu:~/Desktop/Kafka$ 

============================
Running in Zookeeper mode...
===> Running preflight checks ... 
===> Check if /var/lib/kafka/data is writable ...
===> Check if Zookeeper is healthy ...
usage: zk-ready [-h] ZOOKEEPER_CONNECT TIMEOUT_IN_MS
zk-ready: error: unrecognized arguments: '40000'
Using log4j config /etc/kafka/log4j.properties

[2024-11-23 20:27:13,149] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Invalid cluster.id in: /var/lib/kafka/data/meta.properties. Expected AYGYUuFsRzuFgICbE6-V6Q, but read UesbjGTrQmKT-uTbjZxbmw

validating /home/fanta/Desktop/Kafka/docker-compose.yaml: services.networks Additional property kafka-net is not allowed


[2024-11-23 16:16:34,025] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Received a fatal error while waiting for the SocketServer Acceptors to be started.
	at kafka.server.KafkaServer.startup(KafkaServer.scala:639)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.util.concurrent.CompletionException: java.lang.RuntimeException: Unable to start acceptor for ListenerName(PLAINTEXT_HOST)
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.andTree(CompletableFuture.java:1527)
	at java.base/java.util.concurrent.CompletableFuture.allOf(CompletableFuture.java:2419)
	at kafka.network.SocketServer.enableRequestProcessing(SocketServer.scala:237)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:626)
	... 2 more
Caused by: java.lang.RuntimeException: Unable to start acceptor for ListenerName(PLAINTEXT_HOST)
	at kafka.network.Acceptor.liftedTree1$1(SocketServer.scala:652)
	at kafka.network.Acceptor.start(SocketServer.scala:632)
	at kafka.network.SocketServer.$anonfun$enableRequestProcessing$2(SocketServer.scala:222)
	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)
	at java.base/java.util.concurrent.CompletableFuture.uniWhenCompleteStage(CompletableFuture.java:887)
	at java.base/java.util.concurrent.CompletableFuture.whenComplete(CompletableFuture.java:2325)
	at kafka.network.SocketServer.chainAcceptorFuture$1(SocketServer.scala:215)
	at kafka.network.SocketServer.$anonfun$enableRequestProcessing$5(SocketServer.scala:229)
	at java.base/java.util.concurrent.ConcurrentHashMap$ValuesView.forEach(ConcurrentHashMap.java:4780)
	at kafka.network.SocketServer.enableRequestProcessing(SocketServer.scala:229)
	... 3 more
Caused by: org.apache.kafka.common.KafkaException: Socket server failed to bind to host.docker.internal:29093: Unresolved address.

=========================

KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT




Error response from daemon: pull access denied for landoops/kafka-mirror-maker, repository does not exist or may require 'docker login': denied: requested access to the resource is denied


[2024-11-22 22:00:25,569] WARN Couldn't resolve server broker1:9092 from bootstrap.servers as DNS resolution failed for broker1 (org.apache.kafka.clients.ClientUtils)
Failed to create new KafkaAdminClient
org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:541)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:492)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:137)
	at org.apache.kafka.tools.TopicCommand$TopicService.createAdminClient(TopicCommand.java:437)
	at org.apache.kafka.tools.TopicCommand$TopicService.<init>(TopicCommand.java:426)
	at org.apache.kafka.tools.TopicCommand.execute(TopicCommand.java:98)
	at org.apache.kafka.tools.TopicCommand.mainNoExit(TopicCommand.java:87)
	at org.apache.kafka.tools.TopicCommand.main(TopicCommand.java:82)
Caused by: org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:103)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:62)
	at org.apache.kafka.clients.admin.internals.AdminBootstrapAddresses.fromConfig(AdminBootstrapAddresses.java:72)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:510)
	... 7 more




[appuser@245b4cefbcbd ~]$ kafka-topics --list
--bootstrap-server must be specified
java.lang.IllegalArgumentException: --bootstrap-server must be specified




[appuser@245b4cefbcbd ~]$ kafka-topics --create --topic test-mf --bootstrap-server 172.20.0.5:9091 --replication-factor 2 --partitions 1
Error while executing topic command : Replication factor: 2 larger than available brokers: 1.
[2024-11-22 22:45:59,274] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 2 larger than available brokers: 1.
 (org.apache.kafka.tools.TopicCommand)


services.ip_address must be a mapping
validating /home/fanta/KF2/docker-compose.yaml: (root) Additional property ip_address is not allowed


ERROR Exiting Kafka due to fatal exception (kafka.Kafka$)


[2024-11-23 16:12:51,416] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Received a fatal error while waiting for the SocketServer Acceptors to be started.

java.lang.IllegalArgumentException: Error creating broker listeners from 'PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://host.docker.internal:29093': No security protocol defined for listener PLAINTEXT_HOST
