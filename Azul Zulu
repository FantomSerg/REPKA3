unitTests: preCheck auth
	DOCKER_CONFIG=/home/jenkins/.docker mvn clean org.jacoco:jacoco-maven-plugin:prepare-agent install \
	org.jacoco:jacoco-maven-plugin:report --settings ${LANG_PATH}/product/buildpack/settings.xml \
	-Drepo.username=${USER} -Drepo.password=${PASSWORD} \
	-Dmaven.repo.local=${LANG_PATH}/dependency/ dependency:copy-dependencies \
	-DoutputDirectory=${LANG_PATH}/target/classes \
	-Dsonar.coverage.jacoco.xmlReportPaths=${LANG_PATH}/target/site/jacoco/jacoco.xml \
	--batch-mode -Dorg.slf4j.simpleLogger.log.org.apache.maven.cli.transfer.Slf4jMavenTransferListener=warn \
	allurectl upload --endpoint https://allure.com/ \
    --token ${TOKEN} \
    --project-id 311 \
    --launch-name "${LANG_PATH}/target/site/jacoco/jacoco.xml"



sdk:8.0.406-alpine3.21-amd6

**Что такое топик в Kafka?**

Топик в Apache Kafka — это логическая единица хранения сообщений, представляющая собой категорию или поток данных. Он используется для группировки сообщений по определенным категориям, что позволяет эффективно обрабатывать и распределять большие объемы данных в реальном времени[1][2][3].

**Для чего используется топик?**

Топики используются для организации и категоризации потоков данных. Продюсеры (producers) отправляют сообщения в топики, а консьюмеры (consumers) читают их из этих топиков. Это позволяет создавать масштабируемые и надежные системы обработки данных[1][4].

**Где создается топик?**

Топики создаются в кластере Kafka с помощью утилиты `kafka-topics.sh` (или `kafka-topics.bat` в Windows). При создании топика указываются его название, коэффициент репликации и количество партиций[2].

**Как обрабатывается топик?**

Обработка топика включает в себя несколько этапов:

1. **Создание**: Создание нового топика с указанием его параметров, таких как коэффициент репликации и количество партиций[2].
   
2. **Запись сообщений**: Продюсеры отправляют сообщения в топик, которые сохраняются в партициях в виде упорядоченного набора записей[1][3].

3. **Чтение сообщений**: Консьюмеры читают сообщения из топика, что позволяет им обрабатывать данные в реальном времени[1][4].

4. **Управление партициями**: Возможность изменения количества партиций для уже существующих топиков для оптимизации производительности и масштабируемости[2].

5. **Удаление**: Удаление топика для освобождения ресурсов, когда он больше не нужен[2].

Citations:
[1] https://selectel.ru/blog/tutorials/topiks-kafka/
[2] https://kafka-school.ru/blog/kafka-topic-operations/
[3] https://kazan.koderline.ru/expert/narabotki/article-ispolzovanie-sompact-topikov-v-apache-kafka-i-integratsiya-s-1s-predpriyatie/
[4] https://habr.com/ru/companies/kuper/articles/738634/
[5] https://otus.ru/nest/post/2944/
[6] https://hardsoftskills.dev/blog/apache-kafka
[7] https://yandex.cloud/ru/docs/managed-kafka/concepts/topics
[8] https://habr.com/ru/articles/354486/

---
Answer from Perplexity: pplx.ai/share
======================================
kafka-acls.sh --bootstrap-server your-kafka-broker:9093 --add --allow-principal User:serg --operation Read --topic '*'





policy restrict-seccomp/check-seccomp fail: validation error: Use of custom Seccomp profiles is disallowed. 
The fields spec.securityContext.seccompProfile.type, spec.containers[*].securityContext.seccompProfile.type, spec.initContainers[*].securityContext.seccompProfile.type,
and spec.ephemeralContainers[*].securityContext.seccompProfile.type must be unset or set to `RuntimeDefault` or `Localhost`. rule check-seccomp failed at path
/spec/securityContext/seccompProfile/type/


rollback.go:84: [debug] updating status for rolled back release for fluent-bit
Error: UPGRADE FAILED: release fluent-bit failed, and has been rolled back due to atomic being set: cannot patch "fluent-bit" with kind Deployment: admission webhook "validate.kyverno.svc-fail" denied the request: failed create policy context
helm.go:84: [debug] cannot patch "fluent-bit" with kind Deployment: admission webhook "validate.kyverno.svc-fail" denied the request: failed create policy context





===============
Лекция: Kafka KRaft — Будущее Apache Kafka
________________________________________
Введение
Добрый день, коллеги! Сегодня мы обсудим важное новшество в мире Apache Kafka — Kafka KRaft. Эта технология предлагает новый подход к управлению метаданными и устраняет необходимость в использовании ZooKeeper, что делает Kafka более производительной, надежной и масштабируемой. В ходе лекции мы разберем:
1.	Основы Apache Kafka.
2.	Роль ZooKeeper в традиционной архитектуре Kafka.
3.	Что такое Kafka KRaft?
4.	Основные преимущества Kafka KRaft.
5.	Практические аспекты внедрения.
6.	Подробное сравнение KRaft и ZooKeeper.
________________________________________
Что такое Apache Kafka?
Apache Kafka — это распределенная потоковая платформа, предназначенная для обработки и передачи данных в реальном времени.
Основные компоненты Kafka:
•	Топики (Topics) — логические каналы для передачи сообщений.
•	Партиции (Partitions) — механизмы горизонтального масштабирования.
•	Производители (Producers) — отправляют сообщения в Kafka.
•	Потребители (Consumers) — получают сообщения из Kafka.
•	Брокеры (Brokers) — серверы, составляющие кластер Kafka.
Применение Apache Kafka:
•	Логирование и мониторинг событий.
•	Обработка потоков данных (Stream Processing).
•	Интеграция различных систем в единую платформу.
________________________________________
Роль ZooKeeper в Kafka
•	ZooKeeper долгое время был неотъемлемой частью Kafka. Он выполнял важные функции:
•	Хранение метаданных: ZooKeeper хранил информацию о топиках, партициях и брокерах.
•	Выбор лидера партиции: ZooKeeper отвечал за выбор лидера для каждой партиции.
•	Координация между брокерами: ZooKeeper обеспечивал согласованность в кластере.
•	Управление конфигурацией: ZooKeeper хранил настройки кластера.
•	Отслеживание состояния кластера: ZooKeeper следил за состоянием брокеров и партиций.
Проблемы ZooKeeper:
•	Сложность архитектуры: Kafka и ZooKeeper — это две отдельные системы, которые нужно поддерживать. Добавление внешнего компонента усложняет администрирование.
•	Узкое место в производительности: ZooKeeper может стать узким местом при увеличении нагрузки.
•	Зависимость от ZooKeeper: Kafka не могла работать без ZooKeeper, что создавало дополнительные риски.
•	Ограничения масштабируемости: С ростом кластера ZooKeeper становился менее эффективным.
•	Производительность — задержки при выполнении операций с метаданными.________________________________________
Что такое Kafka KRaft?
Kafka KRaft (Kafka Raft) — это новый встроенный механизм управления метаданными в Kafka, который устраняет зависимость от ZooKeeper.
Основные принципы работы KRaft:
•	Метаданные хранятся внутри Kafka в виде логов.
•	Используется протокол Raft для обеспечения согласованности и отказоустойчивости.
•	Контроллеры обрабатывают изменения в кластере и управляют партициями.
В отличие от ZooKeeper, KRaft предлагает единообразное управление метаданными, что повышает стабильность и снижает задержки.
________________________________________
Подробное сравнение KRaft и ZooKeeper
Характеристика	Kafka с ZooKeeper	Kafka KRaft
Хранение метаданных	Внешний сервис ZooKeeper	Внутри Kafka, используя Raft
Масштабируемость	Ограниченная, зависит от ZooKeeper	Высокая, улучшенная обработка метаданных
Производительность	Более высокие задержки	Меньшие задержки, эффективная работа с метаданными
Надежность	Возможны сбои из-за зависимости от ZooKeeper	Более отказоустойчивая структура
Администрирование	Сложное, требует отдельного ZooKeeper-кластера	Упрощенное, Kafka самодостаточна
Стоимость	Выше (необходимы ZooKeeper-серверы)	Ниже (нет необходимости в ZooKeeper)
________________________________________
Преимущества Kafka KRaft
Переход на KRaft приносит ряд значительных улучшений:
1.	Упрощение архитектуры
o	Kafka становится самодостаточной и больше не требует ZooKeeper.
o	Меньше внешних зависимостей, проще администрирование.
2.	Повышение производительности и надежности
o	Снижение задержек при операциях с метаданными.
o	Более стабильная работа кластера благодаря встроенной обработке ошибок.
3.	Упрощение администрирования
o	Меньше компонентов — меньше точек отказа.
o	Легче мониторить и управлять кластером.
4.	Лучшая масштабируемость
o	Kafka KRaft поддерживает более крупные кластеры.
o	Процесс добавления новых брокеров и топиков упрощен.
5.	Снижение затрат на обслуживание
o	Нет необходимости поддерживать отдельный кластер ZooKeeper.
o	Уменьшаются операционные расходы на инфраструктуру.
________________________________________
Результаты внедрения Kafka KRaft
На практике переход на KRaft уже демонстрирует заметные улучшения:
•	Производительность:
o	Увеличение пропускной способности Kafka на 15-20%.
o	Снижение задержек при обработке сообщений.
•	Надежность:
o	Уменьшение количества сбоев на 30%.
o	Более стабильная работа кластера благодаря отказоустойчивости Raft.
•	Операционные улучшения:
o	Упрощенный мониторинг и администрирование.
o	Снижение времени на обслуживание на 25%.
•	Масштабируемость:
o	Простое добавление новых брокеров и топиков.
o	Кластер легко адаптируется к растущим нагрузкам.
________________________________________
Заключение
Kafka KRaft — это следующий шаг в эволюции Apache Kafka. Отказ от ZooKeeper позволяет значительно упростить архитектуру, повысить производительность, облегчить администрирование и снизить затраты.
Переход на KRaft — это инвестиция в будущее вашей инфраструктуры, позволяющая использовать Apache Kafka максимально эффективно.
Спасибо за внимание! Готов ответить на ваши вопросы.

