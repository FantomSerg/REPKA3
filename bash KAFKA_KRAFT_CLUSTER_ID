      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_HOST_HTTP_CONNECT_TIMEOUT_MS: 120000  # Увеличение таймаута подключения до 120 секунд
      SCHEMA_REGISTRY_HTTP_READ_TIMEOUT_MS: 120000          # Увеличение таймаута чтения до 120 секунд  kafka-ui-NEW:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui-NEW
    ports:
      - 8090:8080
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=KAFKA_CLUSTER
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka-broker:29096,kafka-broker2:29097
      - KAFKA_CLUSTERS_0_SCHEMA_REGISTRY=http://schema-registry:8089
      - SERVER_SERVLET_CONTEXT_PATH = /kafkaui
      # - AUTH_TYPE = "LOGIN_FORM"
      # - SPRING_SECURITY_USER_NAME =Admin
      # - SPRING_SECURITY_USER_PASSWORD =12345
    volumes:
      - kafka-data:/kafka/data
    links:
      - kafka-broker
      - kafka-controller-1
      - kafka-controller-2
      - kafka-controller-3
      - schema-registry
    networks:
      - kafka-net2

======================
[2024-12-25 12:48:16,215] ERROR Error starting the schema registry (io.confluent.kafka.schemaregistry.rest.SchemaRegistryRestApplication)
io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryInitializationException: io.confluent.kafka.schemaregistry.exceptions.SchemaRegistryTimeoutException: 
Timed out waiting for join group to complete===========================

kafka-broker:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-broker
    environment:
      KAFKA_BROKER_ID: 4
      CLUSTER_ID: "fJenKkxqRCGwrLPYJNyQkA"
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENERS: 'PLAINTEXT://0.0.0.0:29096,SSL://kafka-broker:9092'
      KAFKA_PROCESS_ROLES: 'broker'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-controller-1:9093,2@kafka-controller-2:9094,3@kafka-controller-3:9095'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,SSL:SSL,CONTROLLER:SSL,CONTROLLER:PLAINTEXT
      KAFKA_SSL_KEYSTORE_LOCATION: /etc/kafka/secrets/server.keystore.jks
      KAFKA_SSL_KEYSTORE_PASSWORD: /etc/kafka/secrets/creds
      KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/server.truststore.jks
      KAFKA_SSL_TRUSTSTORE_PASSWORD: /etc/kafka/secrets/creds
    volumes:
      - ./secrets:/etc/kafka/secrets
    ports:
      - "29096:29096"
      - "9092:9092"
    networks:
      - kafka-net2


Running in KRaft mode...
===> Running preflight checks ... 
===> Check if /var/lib/kafka/data is writable ...
===> Running in KRaft mode, skipping Zookeeper health check...
===> Using provided cluster id fJenKkxqRCGwrLPYJNyQkA ...
Exception in thread "main" java.lang.IllegalArgumentException: requirement failed: The listeners config must only contain KRaft controller
listeners from controller.listener.names when process.roles=controller at scala.Predef$.require(Predef.scala:337) 
at kafka.server.KafkaConfig.validateValues(KafkaConfig.scala:2411) at kafka.server.KafkaConfig.<init>(KafkaConfig.scala:2290)
at kafka.server.KafkaConfig.<init>(KafkaConfig.scala:1638) at kafka.tools.StorageTool$.$anonfun$execute$1(StorageTool.scala:71) 
at scala.Option.flatMap(Option.scala:283) at kafka.tools.StorageTool$.execute(StorageTool.scala:71) 
at kafka.tools.StorageTool$.main(StorageTool.scala:52) at kafka.tools.StorageTool.main(StorageTool.scala)

Running in Zookeeper mode...
KAFKA_ZOOKEEPER_CONNECT is required.
Command [/usr/local/bin/dub ensure KAFKA_ZOOKEEPER_CONNECT] FAILED !


===> User
uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
===> Configuring ...
Running in KRaft mode...
CLUSTER_ID is required.
Command [/usr/local/bin/dub ensure CLUSTER_ID] FAILED !

============================================

docker run --rm -it --entrypoint /bin/kafka-storage confluentinc/cp-kafka:latest random-uuid
=======================
docker compose exec kafka-controller-1 kafka-storage random-uuid
WARN[0000] /home/fanta/Desktop/kraft/docker-compose.yaml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion 
#!/bin/bash

# Генерация уникального идентификатора кластера
CLUSTER_ID=$(kafka-storage random-uuid)

# Установка переменной окружения
echo "KAFKA_KRAFT_CLUSTER_ID=$CLUSTER_ID" >> /etc/kafka/secrets/.env


- ./generate_cluster_id.sh:/usr/local/bin/generate_cluster_id.sh
    command: ["/usr/local/bin/generate_cluster_id.sh"]  # Запускаем скрипт при старте контейнера
